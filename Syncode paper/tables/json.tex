% % \begin{wraptable}{r}{.6\textwidth} 
% \begin{table}[b]
%     \tablesize
%     \centering
%     % \vspace{-0.15in}
%     \caption{Effectiveness of \Tool{} in generating syntactic Go code}
%     \begin{tabular}{@{}ll ccc@{}}
%         \toprule
%         Metric & Prompt Type & \Baseline{} & \Tool{} & $\downarrow$ \\
%         \hline
%          & CodeGen-350M  & 573 & 49 & 91\% \\
%         HumanEval & WizardCoder-1B  & 1031 & 50 & 95\% \\
%         & Llama-7B  & 725 & 10 & 99\% \\
%         \hline
%         & CodeGen-350M  & 212 & 2 & 99\% \\
%         MBXP & WizardCoder-1B  & 243 & 14 & 94\% \\
%         & Llama-7B & 414 & 1 & 99\% \\
        
%         \bottomrule
%     \end{tabular}
%     % \vspace{-0.1in}
%     \label{tab:json_eval}
% % \end{wraptable}
% \end{table}


\begin{table}[htb]
    \tablesize
    \centering
    % \vspace{-0.15in}
    \caption{Effectiveness of \Tool{} in generating JSON with original and explicit prompts.}
    % \begin{tabular}{@{}ll ccc@{}}
    \begin{tabular}{@{}l r r r r r r r@{}}
        \toprule
        % Dataset & Architecture & \Baseline{} & \Tool{} & $\downarrow$ \\
        Model & Tool & \multicolumn{2}{c}{Syntax Errors} & \multicolumn{2}{c}{Validation Accuracy (\%)}
        & \multicolumn{2}{c}{Generation Time (s)}\\
        & & Original & Explicit & Original & Explicit
         & Original & Explicit\\
        % \hline
        \midrule
        & \textbf{\Tool{}}  & \textbf{0} & \textbf{0} & \textbf{66\%} & \textbf{84\%} & \textbf{3.07} & \textbf{3.02} \\

        & \Baseline{}  & 98 & 41 & 2\% & 58\% & 3.58 & 3.11 \\
        Llama-2-7B-chat & \llamacpp{} & 23 & 23 & 63\% & 68\% & 21.91 & 20.84 \\
        & \guidance{} & 13 & 11 & 57\% & 65\% & 5.14 & 4.14 \\
        & \outlines{}$^\dag$  & 16 & 14 & 62\% & 56\% & 38.07 & 41.79 \\
        & \transformerscfg{}  & 2 & 0 & 62\% & 64\% & 6.08 & 4.01 \\
        \midrule

        & \textbf{\Tool{}}  & \textbf{0} & \textbf{0} & \textbf{99\%} & \textbf{100\%} & 4.82 & 4.74 \\

        & \Baseline{}  & 59 & 59 & 41\% & 41\% & 4.32 & 5.82 \\
        Gemma2-2B-it & \llamacpp{} & 7 & 7 & 92\% & 91\% & 22.06 & 21.97 \\
        & \guidance{} & 1 & 1 & 96\% & 96\% & 6.09 & 5.47 \\
        & \outlines{}  & 2 & 0 & 67\% & 90\% & \textbf{1.99} & \textbf{2.64} \\
         & \transformerscfg{}  & 1 & 0 & 96\% & 95\% & 19.12 & 9.49 \\
        
        \bottomrule
    \end{tabular}
    \begin{tablenotes}
    \footnotesize
    \item $\dag$ We observed issues when using Llama-2-7B-chat with Outlines v0.1.1 and therefore, we use older version v0.0.46. 
    
    % use v0.0.46 when running Outlines for Llama-2-7B-chat and v0.1.1 for Gemma2-2B-it as these are the latest releases that give the best performance on these models.
\end{tablenotes}
    % \vspace{-0.1in}
    \label{tab:json_eval}
% \end{wraptable}
\end{table}







